{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d45a0482-a77e-46c6-b85a-26b55669c014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from utils import Utils\n",
    "from utils import spark_utils\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "838aff5e-28af-4116-8759-a720b26e0e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/08/03 20:40:23 WARN Utils: Your hostname, EPCOBOGW1343 resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "24/08/03 20:40:23 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/08/03 20:40:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = spark_utils.get_spark_session(\"DEV\", \"Meli_Datapipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8809778-666d-41d9-afb4-6d1356d87fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_prints = spark.read.json(\"data_sources/prints.json\")\n",
    "df_taps = spark.read.json(\"data_sources/taps.json\")\n",
    "df_pays = spark.read.option(\"header\",\"True\").csv(\"data_sources/pays.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acf3e33e-1c94-4f2f-9429-bceb7cdacb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- day: string (nullable = true)\n",
      " |-- event_data: struct (nullable = true)\n",
      " |    |-- position: long (nullable = true)\n",
      " |    |-- value_prop: string (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_prints.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58af4137-1e02-4eb9-9e47-d87a401fa949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- day: string (nullable = true)\n",
      " |-- event_data: struct (nullable = true)\n",
      " |    |-- position: long (nullable = true)\n",
      " |    |-- value_prop: string (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_taps.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ac39c93-9f76-4e4b-95a7-1b09e22ba56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pay_date: string (nullable = true)\n",
      " |-- total: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- value_prop: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pays.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f55e8d1-bee7-43e3-a2d5-3b24a7aee134",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a109e95-657d-4aba-8bda-3a28d21e3295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(env : str, \n",
    "         appName : str\n",
    "        ):\n",
    "    \n",
    "    spark = spark_utils.get_spark_session(env, appName)\n",
    "    print(type(spark))\n",
    "    df = spark.read.json(\"data_sources/prints.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d493e39-c327-4309-b8f5-395fed8db6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"DEV\", \"Meli_Data_Pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371bc8a2-81d5-46af-9ba1-2338adf3b35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803a4577-cbc6-4ef8-a3aa-7c35266c4c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
